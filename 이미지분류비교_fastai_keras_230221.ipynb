{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEwKwD3DVEWw4ekB7Jwzyy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saykim/ds/blob/main/%EC%9D%B4%EB%AF%B8%EC%A7%80%EB%B6%84%EB%A5%98%EB%B9%84%EA%B5%90_fastai_keras_230221.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "* 각 모델의 성능 비교를 위해서는 각각의 모델을 학습하고 검증하는 과정이 필요합니다. 그래서 일단 두 모델을 간단히 소개하고, 그다음에 해당 모델들을 학습하고 평가하는 과정을 거쳐서 성능을 비교해보도록 하겠습니다.\n",
        "\n",
        "* 먼저, Fastai는 PyTorch를 기반으로 한 딥러닝 라이브러리로, 간단한 코드 작성으로 고수준의 인공지능 모델을 학습할 수 있도록 지원합니다. Fastai는 사용자 친화적인 API와 다양한 이미지 처리 기능을 제공하여 딥러닝 모델 개발에 큰 도움이 됩니다.\n",
        "\n",
        "* 반면에, 위에서 작성한 코드는 Keras를 이용하여 간단한 CNN 모델을 구성하여 이미지 분류 문제를 해결한 것입니다. Keras는 TensorFlow를 기반으로 한 딥러닝 라이브러리로, 사용자 친화적인 API를 제공하여 쉽게 딥러닝 모델을 구성할 수 있습니다.\n",
        "\n",
        "* Fastai와 Keras 모두 이미지 분류 문제를 해결하는 데에 적합한 라이브러리이지만, 성능 측면에서는 데이터셋의 특성에 따라 다를 수 있습니다. 따라서 고양이와 개 분류 문제를 해결할 때, 두 라이브러리 모두 좋은 성능을 보일 것으로 예상됩니다.\n",
        "\n",
        "* 하지만, 엑스레이 이미지 분류 문제에서는 성능에 차이가 발생할 수 있습니다. 이는 엑스레이 이미지 분류 문제가 고양이와 개 분류 문제와는 데이터의 특성이 달라서 발생할 수 있는 현상입니다. 엑스레이 이미지는 고해상도의 이미지가 많고, 이미지 내부에 다양한 패턴과 텍스처가 존재하기 때문에 고차원적인 특징을 추출하고 분류하는 능력이 필요합니다. 따라서, 이러한 고차원적인 특징 추출 능력이 좋은 모델이 더 나은 성능을 보일 것으로 예상됩니다.\n",
        "\n",
        "* 이제 각 라이브러리에서 고양이와 개 이미지 분류 문제와 엑스레이 이미지 분류 문제를 해결하는 모델을 학습하고 평가하여 성능을 비교해보도록 하겠습니다.\n"
      ],
      "metadata": {
        "id": "Id4-lvxTUDmm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fastai"
      ],
      "metadata": {
        "id": "pePFetAHUYUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.vision.all import *\n",
        "\n",
        "path = untar_data(URLs.PETS)/'images'\n",
        "\n",
        "def is_cat(x):\n",
        "    return x[0].isupper()\n",
        "\n",
        "dls = ImageDataLoaders.from_name_func(path, get_image_files(path), valid_pct=0.2, seed=42, \n",
        "                                      label_func=is_cat, item_tfms=Resize(460), batch_tfms=aug_transforms(size=224, min_scale=0.75))\n",
        "\n",
        "learn = cnn_learner(dls, resnet34, metrics=accuracy)\n",
        "learn.fine_tune(1)\n"
      ],
      "metadata": {
        "id": "nULRMs8IUk8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 위 코드는 Fastai를 이용하여 고양이와 개 이미지 분류 문제를 해결하는 모델을 학습하고 평가한 결과입니다. 데이터셋으로는 fastai 라이브러리에서 제공하는 PETS 데이터셋을 이용하였습니다. is_cat 함수를 이용하여 레이블을 지정하고, ImageDataLoaders를 이용하여 데이터셋을 불러왔습니다. 모델은 resnet34를 이용하였으며, fine_tune 메서드를 이용하여 모델을 학습하였습니다."
      ],
      "metadata": {
        "id": "WFyUW5f-UnfK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keras"
      ],
      "metadata": {
        "id": "nAydpdALUocy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "img_width, img_height = 150, 150\n",
        "train_data_dir = 'data/train'\n",
        "validation_data_dir = 'data/validation'\n",
        "nb_train_samples = 2000\n",
        "nb_validation_samples = 800\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(img_width, img_height, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode='binary')\n",
        "validation_generator = test_datagen.flow_from_directory(validation_data_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode='binary')\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size,\n",
        "    class_weight=class_weight,\n",
        "    callbacks=[early_stopping]\n",
        ")\n"
      ],
      "metadata": {
        "id": "FRKRrlwvUqBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 위 코드에서는 EarlyStopping 콜백 함수를 이용하여 val_loss 값이 3번 이상 개선되지 않으면 학습을 중단합니다. fit_generator 함수를 이용하여 학습을 수행하며, class_weight를 이용하여 클래스 불균형 문제를 해결하였습니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "UUG3v02hVRj2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델간 비교"
      ],
      "metadata": {
        "id": "HFcp78yXVR4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 고양이와 개 이미지 분류 문제 평가\n",
        "loss, acc = learn.validate()\n",
        "print(f'Fastai model accuracy: {acc*100:.2f}%')\n",
        "\n",
        "score = model.evaluate_generator(validation_generator, nb_validation_samples // batch_size)\n",
        "print(f'Keras model accuracy: {score[1]*100:.2f}%')\n",
        "\n",
        "# 엑스레이 이미지 분류 문제 평가\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "def predict_image(model, img_path):\n",
        "    img = image.load_img(img_path, target_size=(img_width, img_height))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x /= 255.\n",
        "\n",
        "    pred = model.predict(x)[0][0]\n",
        "    return 'Positive' if pred > 0.5 else 'Negative'\n",
        "\n",
        "xray_model = load_model('xray_model.h5')\n",
        "xray_model.evaluate(x_test, y_test)\n",
        "\n",
        "# 예측\n",
        "predict_image(xray_model, 'xray_image.png')\n"
      ],
      "metadata": {
        "id": "w_vIC7dWVR6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 위 코드에서는 먼저 고양이와 개 이미지 분류 문제에서 각 모델의 성능을 측정합니다. Fastai 모델은 validate 메서드를 이용하여 성능을 측정하였으며, Keras 모델은 evaluate_generator 함수를 이용하여 성능을 측정하였습니다. 두 모델의 성능은 각각 acc와 score[1] 값으로 확인할 수 있습니다."
      ],
      "metadata": {
        "id": "IDwk4ce4VR8d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 또한, 엑스레이 이미지 분류 문제에서는 미리 학습된 모델을 불러와서 성능을 평가하였습니다. load_model 함수를 이용하여 불러온 모델은 evaluate 메서드를 이용하여 성능을 측정하였습니다. 이후, predict_image 함수를 이용하여 샘플 이미지의 분류 결과를 예측하였습니다.\n",
        "\n",
        "\n",
        "\n",
        "이렇게 성능을 측정하여 두 모델의 성능을 비교할 수 있습니다."
      ],
      "metadata": {
        "id": "uE5402b9VR-W"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QuC5FDmiVSAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UPY42OsvVSCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "alaX2m92VSEb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}