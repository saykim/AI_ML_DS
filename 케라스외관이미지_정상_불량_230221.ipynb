{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNizbhrG6FGSJsbjyhYkxQ6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saykim/ds/blob/main/%EC%BC%80%EB%9D%BC%EC%8A%A4%EC%99%B8%EA%B4%80%EC%9D%B4%EB%AF%B8%EC%A7%80_%EC%A0%95%EC%83%81_%EB%B6%88%EB%9F%89_230221.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 케라스 모델로 외관불량 이미지 분류\n",
        "* 케라스 함수형 사용\n",
        "* 이미지 변형\n",
        "* "
      ],
      "metadata": {
        "id": "YdwyAh_-MdgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WWFmtUH6E6vC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 경로\n",
        "train_path = 'train/*.jpg'\n",
        "test_path = 'test/*.jpg'\n",
        "\n",
        "# 이미지 크기\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "# 입력 이미지 크기\n",
        "input_shape = (img_width, img_height, 3)\n",
        "\n",
        "# 불러올 이미지 개수\n",
        "nb_train_samples = len(glob.glob(train_path))\n",
        "nb_test_samples = len(glob.glob(test_path))\n",
        "\n",
        "# 클래스 개수\n",
        "nb_classes = 2\n",
        "\n",
        "# 데이터 증강\n",
        "datagen_train = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "# 학습 데이터셋 생성\n",
        "x_train = np.zeros((nb_train_samples * 11, img_width, img_height, 3), dtype=np.float32)\n",
        "y_train = np.zeros((nb_train_samples * 11, nb_classes), dtype=np.float32)\n",
        "\n",
        "i = 0\n",
        "for file in glob.glob(train_path):\n",
        "    img = load_img(file, target_size=(img_width, img_height))\n",
        "    img_array = img_to_array(img)\n",
        "    x_train[i] = img_array\n",
        "\n",
        "    label = os.path.basename(file).split('_')[0]\n",
        "    if label == '정상':\n",
        "        y_train[i][0] = 1\n",
        "    else:\n",
        "        y_train[i][1] = 1\n",
        "    i += 1\n",
        "\n",
        "    img_aug = img_array.reshape((1,) + img_array.shape)\n",
        "    for batch in datagen_train.flow(img_aug, batch_size=1):\n",
        "        x_train[i] = batch[0]\n",
        "        if label == '정상':\n",
        "            y_train[i][0] = 1\n",
        "        else:\n",
        "            y_train[i][1] = 1\n",
        "        i += 1\n",
        "        if i % nb_train_samples == 0:\n",
        "            break\n",
        "\n",
        "# 검증 데이터셋 생성\n",
        "x_test = np.zeros((nb_test_samples, img_width, img_height, 3), dtype=np.float32)\n",
        "y_test = np.zeros((nb_test_samples, nb_classes), dtype=np.float32)\n",
        "\n",
        "i = 0\n",
        "for file in glob.glob(test_path):\n",
        "    img = load_img(file, target_size=(img_width, img_height))\n",
        "    img_array = img_to_array(img)\n",
        "    x_test[i] = img_array\n",
        "\n",
        "    label = os.path.basename(file).split('_')[0]\n",
        "    if label == '정상':\n",
        "        y_test[i][0] = 1\n",
        "    else:\n",
        "        y_test[i][1] = 1\n",
        "    i += 1\n",
        "\n",
        "# 모델 아키텍처\n",
        "inputs = Input(shape=input_shape)\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "flatten = Flatten()(pool3)\n",
        "fc1 = Dense(512, activation='relu')(flatten)\n",
        "fc2 = Dense(256, activation='relu')(fc1)\n",
        "outputs = Dense(nb_classes, activation='softmax')(fc2)"
      ],
      "metadata": {
        "id": "j1fKpgjOMH7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "PoDxpupmMIFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)"
      ],
      "metadata": {
        "id": "A604ewV0MIHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, batch_size=32, epochs=100, validation_data=(x_test, y_test), callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "cEKQgH-IMIJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8WxmYQYnMILo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "VqT38IKhMINt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "md9dqHFwMcUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 불량, 정상간의 데이터 불균형"
      ],
      "metadata": {
        "id": "AEewneUgMIQD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">만약 외관 이미지 불량이 전체 생산량 중에 0.1%도 발생하지 않는다면, 데이터 불균형 \n",
        "문제가 발생합니다. 이런 경우, 모델이 정상이라고 예측하는 경우가 매우 높아지기 때문에, 정상인 경우에 대한 예측력이 높아지는 결과를 초래할 수 있습니다.\n",
        "\n",
        ">이를 해결하기 위해서는 데이터셋의 불균형을 해소할 필요가 있습니다. 데이터셋의 불균형 문제를 해결하기 위해서는 데이터를 증강하는 방법 외에도, 언더샘플링, 오버샘플링, 클래스 가중치 적용 등의 방법을 이용할 수 있습니다. 이 중에서 클래스 가중치 적용 방법을 적용하여 최적화한 코드를 작성해보겠습니다."
      ],
      "metadata": {
        "id": "Fzgn1goIPJp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# 이미지 경로\n",
        "train_path = 'train/*.jpg'\n",
        "test_path = 'test/*.jpg'\n",
        "\n",
        "# 이미지 크기\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "# 입력 이미지 크기\n",
        "input_shape = (img_width, img_height, 3)\n",
        "\n",
        "# 불러올 이미지 개수\n",
        "nb_train_samples = len(glob.glob(train_path))\n",
        "nb_test_samples = len(glob.glob(test_path))\n",
        "\n",
        "# 클래스 개수\n",
        "nb_classes = 2\n",
        "\n",
        "# 데이터 증강\n",
        "datagen_train = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "# 학습 데이터셋 생성\n",
        "x_train = np.zeros((nb_train_samples * 11, img_width, img_height, 3), dtype=np.float32)\n",
        "y_train = np.zeros((nb_train_samples * 11, nb_classes), dtype=np.float32)\n",
        "\n",
        "i = 0\n",
        "count_defect = 0\n",
        "for file in glob.glob(train_path):\n",
        "    img = load_img(file, target_size=(img_width, img_height))\n",
        "    img_array = img_to_array(img)\n",
        "    x_train[i] = img_array\n",
        "\n",
        "    label = os.path.basename(file).split('_')[0]\n",
        "    if label == '정상':\n",
        "        y_train[i][0] = 1\n",
        "    else:\n",
        "        y_train[i][1] = 1\n",
        "        count_defect += 1\n",
        "    i += 1\n",
        "\n",
        "    img_aug = img_array.reshape((1,) + img_array.shape)\n",
        "    for batch in datagen_train.flow(img_aug, batch_size=1):\n",
        "        x_train[i] = batch[0]\n",
        "        if label == '정상':\n",
        "            y_train[i][0] = 1\n",
        "        else:\n",
        "            y_train[i][1] = 1\n",
        "            count_defect += 1\n",
        "        i += 1\n",
        "        if i % nb_train_samples == 0:\n",
        "            break\n",
        "\n",
        "#클래스 가중치 계산\n",
        "class_weight = {0: 1, 1: nb_train_samples / count_defect}\n",
        "\n",
        "#검증 데이터셋 생성\n",
        "x_test = np.zeros((nb_test_samples, img_width, img_height, 3), dtype=np.float32)\n",
        "y_test = np.zeros((nb_test_samples, nb_classes), dtype=np.float32)\n",
        "\n",
        "i = 0\n",
        "for file in glob.glob(test_path):\n",
        "img = load_img(file, target_size=(img_width, img_height))\n",
        "img_array = img_to_array(img)\n",
        "x_test[i] = img_array\n",
        "\n",
        "label = os.path.basename(file).split('_')[0]\n",
        "if label == '정상':\n",
        "    y_test[i][0] = 1\n",
        "else:\n",
        "    y_test[i][1] = 1\n",
        "i += 1\n"
      ],
      "metadata": {
        "id": "nIj_qJGNPG5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 아케텍처\n",
        "\n",
        "inputs = Input(shape=input_shape)\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "flatten = Flatten()(pool3)\n",
        "fc1 = Dense(512, activation='relu')(flatten)\n",
        "fc2 = Dense(256, activation='relu')(fc1)\n",
        "outputs = Dense(nb_classes, activation='softmax')(fc2)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#조기 종료\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "\n",
        "#학습\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=100, validation_data=(x_test, y_test), \\\n",
        "          class_weight=class_weight, callbacks=[early_stopping])\n",
        "\n",
        "#평가\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ],
      "metadata": {
        "id": "m2aLKYIHPmCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weight = {0: 1, 1: nb_train_samples / count_defect}\n",
        "\n",
        "#여기서, 클래스 0은 정상, 클래스 1은 불량을 나타내는 라벨입니다.\n",
        "#클래스 0은 1로, 클래스 1은 전체 학습 데이터셋에서 불량 이미지의 비율로 가중치를 부여합니다. \n",
        "#이렇게 계산된 클래스 가중치는 모델 학습 시 fit() 메서드에서 class_weight 매개변수로 전달합니다."
      ],
      "metadata": {
        "id": "iWnYApNkQm1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=100, validation_data=(x_test, y_test), \\\n",
        "          class_weight=class_weight, callbacks=[early_stopping])\n",
        "\n",
        "# 평가\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "zhm2zhgKQO3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 최종 완성코드"
      ],
      "metadata": {
        "id": "XQZCMMjyRidE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# 이미지 경로\n",
        "train_path = 'train/*.jpg'\n",
        "test_path = 'test/*.jpg'\n",
        "\n",
        "# 이미지 크기\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "# 입력 이미지 크기\n",
        "input_shape = (img_width, img_height, 3)\n",
        "\n",
        "# 불러올 이미지 개수\n",
        "nb_train_samples = len(glob.glob(train_path))\n",
        "nb_test_samples = len(glob.glob(test_path))\n",
        "\n",
        "# 클래스 개수\n",
        "nb_classes = 2\n",
        "\n",
        "# 데이터 증강\n",
        "datagen_train = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "# 학습 데이터셋 생성\n",
        "x_train = np.zeros((nb_train_samples * 11, img_width, img_height, 3), dtype=np.float32)\n",
        "y_train = np.zeros((nb_train_samples * 11, nb_classes), dtype=np.float32)\n",
        "\n",
        "i = 0\n",
        "count_defect = 0\n",
        "for file in glob.glob(train_path):\n",
        "    img = load_img(file, target_size=(img_width, img_height))\n",
        "    img_array = img_to_array(img)\n",
        "    x_train[i] = img_array\n",
        "\n",
        "    label = os.path.basename(file).split('_')[0]\n",
        "    if label == '정상':\n",
        "        y_train[i][0] = 1\n",
        "    else:\n",
        "        y_train[i][1] = 1\n",
        "        count_defect += 1\n",
        "    i += 1\n",
        "\n",
        "    img_aug = img_array.reshape((1,) + img_array.shape)\n",
        "    for batch in datagen_train.flow(img_aug, batch_size=1):\n",
        "        x_train[i] = batch[0]\n",
        "        if label == '정상':\n",
        "            y_train[i][0] = 1\n",
        "        else:\n",
        "            y_train[i][1] = 1\n",
        "            count_defect += 1\n",
        "        i += 1\n",
        "        if i % nb_train_samples == 0:\n",
        "            break\n",
        "\n",
        "# 클래스 가중치 계산\n",
        "class_weight = {0: 1, 1: nb_train_samples / count_defect}\n",
        "\n",
        "# 검증 데이터셋 생성\n",
        "x_test = np.zeros((nb_test_samples, img_width, img_height, 3), dtype=np.float32)\n",
        "y_test = np.zeros((nb_test_samples, nb_classes), dtype=np.float32)\n",
        "\n",
        "i = 0\n",
        "for file in glob.glob(test_path):\n",
        "    img = load_img(file, target_size=(img_width, img_height))\n",
        "    img_array = img_to_array(img)\n",
        "    x_test[i] = img_array\n",
        "\n",
        "    label = os.path.basename(file).split('_')[0]\n",
        "    if label == '정상':\n",
        "        y_test[i][0] = 1\n",
        "    else:\n",
        "        y_test[i][1] = 1\n",
        "    i += 1\n",
        "\n",
        "# 모델 아키텍처\n",
        "inputs = Input(shape=input_shape)\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "flatten = Flatten()(pool3)\n",
        "fc1 = Dense(512, activation='relu')(flatten)\n",
        "fc2 = Dense(256, activation='relu')(fc1)\n",
        "outputs = Dense(nb_classes, activation='softmax')(fc2)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 조기 종료\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "# 학습\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=100, validation_data=(x_test, y_test), class_weight=class_weight, callbacks=[early_stopping])\n",
        "\n",
        "# 평가\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ],
      "metadata": {
        "id": "pvlkYCqQRie1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 그래프로 확인"
      ],
      "metadata": {
        "id": "jtszuoypRig-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 학습 결과 저장\n",
        "history = model.fit(x_train, y_train, batch_size=32, epochs=100, validation_data=(x_test, y_test), class_weight=class_weight, callbacks=[early_stopping])\n",
        "\n",
        "# 손실 그래프\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "# 정확도 그래프\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'val'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#위 코드를 실행하면 학습 결과를 저장한 history 객체를 이용하여 손실 그래프와 정확도 그래프를 그릴 수 있습니다."
      ],
      "metadata": {
        "id": "rdOReTz5Rii6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pDhXNIgkRikX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}